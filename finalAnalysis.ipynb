{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050f54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from data_utils import preprocessDataset\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import copy\n",
    "from aif360.metrics import ClassificationMetric\n",
    "import math\n",
    "plt.rcParams['axes.ymargin'] = 0.5\n",
    "plt.rcParams['axes.axisbelow'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBayesOptimalResults(dim=100):\n",
    "    with open('/media/data_dump/anonymous/aaai_2023_data/synthetic/means.pkl', 'rb') as f:\n",
    "        means = pickle.load(f)\n",
    "    _, test_dataset_original = preprocessDataset('/media/data_dump/anonymous/aaai_2023_data/synthetic/raw/original_train.csv', '/media/data_dump/anonymous/aaai_2023_data/synthetic/raw/original_test.csv', 'synthetic')\n",
    "    x = test_dataset_original.features[:,:-1]\n",
    "    z = test_dataset_original.protected_attributes.squeeze()\n",
    "    y = []\n",
    "    var = 1\n",
    "    #group_0_0_pdf = np.random.multivariate_normal(mean=means[0], cov=var*np.eye(1))\n",
    "    #group_0_1_pdf = np.random.multivariate_normal(mean=means[1], cov=var*np.eye(1))\n",
    "    #group_1_0_pdf = np.random.multivariate_normal(mean=means[2], cov=var*np.eye(1))\n",
    "    #group_1_1_pdf = np.random.multivariate_normal(mean=means[3], cov=var*np.eye(1))\n",
    "    for i in range(len(x)):\n",
    "        if z[i] == 0:\n",
    "            # first index y, second z\n",
    "            pdf_0_0 = multivariate_normal.pdf(x[i], mean=means[0], cov=var*np.eye(dim))\n",
    "            pdf_1_0 = multivariate_normal.pdf(x[i], mean=means[2], cov=var*np.eye(dim))\n",
    "            if pdf_0_0 > pdf_1_0:\n",
    "                y.append(0)\n",
    "            else:\n",
    "                y.append(1)\n",
    "        elif z[i] == 1:\n",
    "            # first index y, second z\n",
    "            pdf_0_1 = multivariate_normal.pdf(x[i], mean=means[1], cov=var*np.eye(dim))\n",
    "            pdf_1_1 = multivariate_normal.pdf(x[i], mean=means[3], cov=var*np.eye(dim))\n",
    "            if pdf_0_1 > pdf_1_1:\n",
    "                y.append(0)\n",
    "            else:\n",
    "                y.append(1)\n",
    "#     for i in range(len(x)):\n",
    "#         pdfs = [multivariate_normal.pdf(x[i], mean=means[0], cov=var*np.eye(dim)),\n",
    "#         multivariate_normal.pdf(x[i], mean=means[1], cov=var*np.eye(dim)),\n",
    "#         multivariate_normal.pdf(x[i], mean=means[2], cov=var*np.eye(dim)),\n",
    "#         multivariate_normal.pdf(x[i], mean=means[3], cov=var*np.eye(dim))]\n",
    "#         correctIndex = np.argmax(pdfs)\n",
    "#         if correctIndex == 0 or correctIndex == 1:\n",
    "#             y.append(0)\n",
    "#         elif correctIndex == 2 or correctIndex == 3:\n",
    "#             y.append(1)\n",
    "    pred_test_set = copy.deepcopy(test_dataset_original)\n",
    "    pred_test_set.labels = np.asarray(y)\n",
    "    privileged_groups = [{'sensitive':1}]\n",
    "    unprivileged_groups = [{'sensitive': 0}]\n",
    "    return ClassificationMetric(test_dataset_original, pred_test_set, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09191b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_mean_plots(files, metric='eod', testSet='orig', dataset='synthetic', statType='mean', plotLimits=None, lessBiasMode=False):\n",
    "    if dataset == 'compas':\n",
    "        omitCls = ['meta_fair_fdr']\n",
    "    else:\n",
    "        omitCls = []\n",
    "    axisTitles = {\n",
    "        'dp': 'Statistical Parity Diff.',\n",
    "        'eod': 'Equal Opportunity Difference'\n",
    "    }\n",
    "    markers = {\n",
    "        'lr': '+',\n",
    "        'jiang_nachum': 'o',\n",
    "        'rew':'o',\n",
    "        'fairgan':'o',\n",
    "        'exp_grad_eodds':'^',\n",
    "        'meta_fair_fdr':'^',\n",
    "        'prej_remover':'^',\n",
    "        'gerry_fair': '^',\n",
    "        'cal_eq':'s',\n",
    "        'eq':'s',\n",
    "        'reject':'s'\n",
    "    }\n",
    "    colors = {\n",
    "        'lr': '#1f77b4',\n",
    "        'jiang_nachum': '#ff7f0e',\n",
    "        'rew':'#2ca02c',\n",
    "        'fairgan':'#d62728',\n",
    "        'exp_grad_eodds':'#9467bd',\n",
    "        'meta_fair_fdr':'#8c564b',\n",
    "        'prej_remover':'#e377c2',\n",
    "        'gerry_fair': '#7f7f7f',\n",
    "        'cal_eq':'#bcbd22',\n",
    "        'eq':'#17becf',\n",
    "        'reject':'#1f77b4'\n",
    "    }\n",
    "    fig, ax = plt.subplots(ncols=4)\n",
    "    fig.subplots_adjust(wspace=0.4)\n",
    "    fig.set_figheight(3)\n",
    "    fig.set_figwidth(12)\n",
    "    overallStats = {}\n",
    "    fixed_bp_variable_bn_stats = {}\n",
    "    fixed_bn_variable_bp_stats = {}\n",
    "    for file in files:\n",
    "        if file == 'base':\n",
    "            file = 'lr'\n",
    "        if file not in omitCls:\n",
    "            overallStats[file] = [[],[]]\n",
    "            fixed_bp_variable_bn_stats[file] = [[],[]]\n",
    "            fixed_bn_variable_bp_stats[file] = [[],[]]\n",
    "    if lessBiasMode == True:\n",
    "        start_range = 5\n",
    "    else:\n",
    "        start_range = 1\n",
    "    end_range = 11\n",
    "    for bp,beta_pos in enumerate(range(start_range,11)):\n",
    "        beta_pos /= 10\n",
    "        for bn,beta_neg in enumerate(range(start_range,11)):\n",
    "            beta_neg /= 10\n",
    "            # Calculating required Quantities\n",
    "            for file in files:\n",
    "                if file in omitCls:\n",
    "                    continue\n",
    "                results = files[file]\n",
    "                try:\n",
    "                    if metric == 'dp':\n",
    "                        y_bal = abs(results['undersample'][f'imbalance_{str(beta_pos)}_{str(beta_neg)}']['balanced'].statistical_parity_difference())\n",
    "                        y_biased = abs(results['undersample'][f'imbalance_{str(beta_pos)}_{str(beta_neg)}']['biased'].statistical_parity_difference())\n",
    "                        y_orig = abs(results['undersample'][f'imbalance_{str(beta_pos)}_{str(beta_neg)}']['original'].statistical_parity_difference())\n",
    "                    elif metric == 'eod':\n",
    "                        y_bal = abs(results['undersample'][f'imbalance_{str(beta_pos)}_{str(beta_neg)}']['balanced'].equal_opportunity_difference())\n",
    "                        y_biased = abs(results['undersample'][f'imbalance_{str(beta_pos)}_{str(beta_neg)}']['biased'].equal_opportunity_difference())\n",
    "                        y_orig = abs(results['undersample'][f'imbalance_{str(beta_pos)}_{str(beta_neg)}']['original'].equal_opportunity_difference())\n",
    "                    # Calculate accuracy\n",
    "                    x_err_rate_bal = (1 - abs(results['undersample'][f'imbalance_{str(beta_pos)}_{str(beta_neg)}']['balanced'].accuracy()))\n",
    "                    x_err_rate_biased = (1 - abs(results['undersample'][f'imbalance_{str(beta_pos)}_{str(beta_neg)}']['biased'].accuracy()))\n",
    "                    x_err_rate_orig = (1 - abs(results['undersample'][f'imbalance_{str(beta_pos)}_{str(beta_neg)}']['original'].accuracy()))\n",
    "                except TypeError as te:\n",
    "                    continue\n",
    "                if testSet == 'bal':\n",
    "                    y = y_bal\n",
    "                    x = x_err_rate_bal\n",
    "                elif testSet == 'biased':\n",
    "                    y = y_biased\n",
    "                    x = x_err_rate_biased\n",
    "                elif testSet == 'orig':\n",
    "                    y = y_orig\n",
    "                    x = x_err_rate_orig\n",
    "                # Renaming 'base' to 'lr'\n",
    "                if file == 'base':\n",
    "                    file = 'lr'\n",
    "                    overallStats[file][0].append(x)\n",
    "                    overallStats[file][1].append(y)\n",
    "                    if beta_pos == 1.0:\n",
    "                        fixed_bp_variable_bn_stats[file][0].append(x)\n",
    "                        fixed_bp_variable_bn_stats[file][1].append(y)\n",
    "                    if beta_neg == 1.0:\n",
    "                        fixed_bn_variable_bp_stats[file][0].append(x)\n",
    "                        fixed_bn_variable_bp_stats[file][1].append(y)\n",
    "                else:\n",
    "                    overallStats[file][0].append(x)\n",
    "                    overallStats[file][1].append(y)\n",
    "                    if beta_pos == 1.0:\n",
    "                        fixed_bp_variable_bn_stats[file][0].append(x)\n",
    "                        fixed_bp_variable_bn_stats[file][1].append(y)\n",
    "                    if beta_neg == 1.0:\n",
    "                        fixed_bn_variable_bp_stats[file][0].append(x)\n",
    "                        fixed_bn_variable_bp_stats[file][1].append(y)\n",
    "    ##############\n",
    "    # Overall Mean\n",
    "    ##############\n",
    "    del overallStats['lr']\n",
    "    for i in overallStats:\n",
    "        if statType == 'max':\n",
    "            ax[1].errorbar(x=max(overallStats[i][0]), y=max(overallStats[i][1]), label=i, fmt=markers[i], color=colors[i])\n",
    "        else:\n",
    "            if np.mean(overallStats[i][0]) > plotLimits[dataset][0][1] or np.mean(overallStats[i][1]) > plotLimits[dataset][1][1]:\n",
    "                ax[1].errorbar(x=np.mean(overallStats[i][0]), y=np.mean(overallStats[i][1]), label=i, fmt=markers[i], color=colors[i])\n",
    "            else:\n",
    "                temp = ax[1].errorbar(x=np.mean(overallStats[i][0]), y=np.mean(overallStats[i][1]), xerr=np.std(overallStats[i][0]), yerr=np.std(overallStats[i][1]), label=i, fmt=markers[i], color=colors[i])\n",
    "                [bar.set_alpha(0.3) for bar in temp[2]]\n",
    "                [cap.set_alpha(0.3) for cap in temp[1]]\n",
    "        ax[1].set_ylim(plotLimits[dataset][1])\n",
    "        ax[1].set_xlim(plotLimits[dataset][0])\n",
    "    # D2 distribution lines\n",
    "    #if dataset != 'synthetic':\n",
    "    if metric == 'eod':\n",
    "        ax[1].axvline(x=(1.0 - files['base']['undersample']['imbalance_1.0_1.0']['original'].accuracy()))\n",
    "        ax[1].axhline(y=abs(files['base']['undersample']['imbalance_1.0_1.0']['original'].equal_opportunity_difference()))\n",
    "    elif metric == 'dp':\n",
    "        ax[1].axvline(x=(1.0 - files['base']['undersample']['imbalance_1.0_1.0']['original'].accuracy()))\n",
    "        ax[1].axhline(y=abs(files['base']['undersample']['imbalance_1.0_1.0']['original'].statistical_parity_difference()))\n",
    "    ax[1].set_xlabel('Error Rate')\n",
    "    #ax[1].set_ylabel(axisTitles[metric])\n",
    "    ax[1].set_title('Mean Over all settings', fontsize=10)\n",
    "#     else:\n",
    "#         bayes_optimal_results = getBayesOptimalResults()\n",
    "#         if metric == 'eod':\n",
    "#             ax[1].axvline(x=(1.0 - bayes_optimal_results.accuracy()))\n",
    "#             ax[1].axhline(y=abs(bayes_optimal_results.equal_opportunity_difference()))\n",
    "#         elif metric == 'dp':\n",
    "#             ax[1].axvline(x=(1.0 - bayes_optimal_results.accuracy()))\n",
    "#             ax[1].axhline(y=abs(bayes_optimal_results.statistical_parity_difference()))\n",
    "#         ax[1].set_xlabel('Error Rate')\n",
    "#         ax[1].set_ylabel(axisTitles[metric])\n",
    "#         ax[1].set_title('Mean Over all settings', fontsize=10)\n",
    "\n",
    "    #######################\n",
    "    # BP fixed, BN variable\n",
    "    #######################\n",
    "    del fixed_bp_variable_bn_stats['lr']\n",
    "    for i in fixed_bp_variable_bn_stats:\n",
    "        if statType == 'max':\n",
    "            ax[2].errorbar(x=max(fixed_bp_variable_bn_stats[i][0]), y=max(fixed_bp_variable_bn_stats[i][1]), label=i, fmt=markers[i], color=colors[i])\n",
    "        else:\n",
    "            if np.mean(fixed_bp_variable_bn_stats[i][0]) > plotLimits[dataset][0][1] or np.mean(fixed_bp_variable_bn_stats[i][1]) > plotLimits[dataset][1][1]:\n",
    "                ax[2].errorbar(x=np.mean(fixed_bp_variable_bn_stats[i][0]), y=np.mean(fixed_bp_variable_bn_stats[i][1]), label=i, fmt=markers[i], color=colors[i])\n",
    "            else:\n",
    "                temp = ax[2].errorbar(x=np.mean(fixed_bp_variable_bn_stats[i][0]), xerr=np.std(fixed_bp_variable_bn_stats[i][0]), y=np.mean(fixed_bp_variable_bn_stats[i][1]), yerr=np.std(fixed_bp_variable_bn_stats[i][1]), label=i, fmt=markers[i], color=colors[i])\n",
    "                [bar.set_alpha(0.3) for bar in temp[2]]\n",
    "                [cap.set_alpha(0.3) for cap in temp[1]]\n",
    "        ax[2].set_ylim(plotLimits[dataset][1])\n",
    "        ax[2].set_xlim(plotLimits[dataset][0])\n",
    "    # D2 distribution lines\n",
    "    #if dataset != 'synthetic':\n",
    "    if metric == 'eod':\n",
    "        ax[2].axvline(x=(1.0 - files['base']['undersample']['imbalance_1.0_1.0']['original'].accuracy()))\n",
    "        ax[2].axhline(y=abs(files['base']['undersample']['imbalance_1.0_1.0']['original'].equal_opportunity_difference()))\n",
    "    elif metric == 'dp':\n",
    "        ax[2].axvline(x=(1.0 - files['base']['undersample']['imbalance_1.0_1.0']['original'].accuracy()))\n",
    "        ax[2].axhline(y=abs(files['base']['undersample']['imbalance_1.0_1.0']['original'].statistical_parity_difference()))\n",
    "    ax[2].set_xlabel('Error Rate')\n",
    "    #ax[2].set_ylabel(axisTitles[metric])\n",
    "    ax[2].set_title(r'Mean over all $β_{pos}$=1.0', fontsize=10)\n",
    "    #else:\n",
    "#     bayes_optimal_results = getBayesOptimalResults()\n",
    "#     if metric == 'eod':\n",
    "#         ax[2].axvline(x=(1.0 - bayes_optimal_results.accuracy()))\n",
    "#         ax[2].axhline(y=abs(bayes_optimal_results.equal_opportunity_difference()))\n",
    "#     elif metric == 'dp':\n",
    "#         ax[2].axvline(x=(1.0 - bayes_optimal_results.accuracy()))\n",
    "#         ax[2].axhline(y=abs(bayes_optimal_results.statistical_parity_difference()))\n",
    "#     ax[2].set_xlabel('Error Rate')\n",
    "#     ax[2].set_ylabel(axisTitles[metric])\n",
    "#     ax[2].set_title(r'Mean over all $β_{pos}$=1.0', fontsize=10)\n",
    "    \n",
    "    #######################\n",
    "    # BN fixed, BP variable\n",
    "    #######################\n",
    "    del fixed_bn_variable_bp_stats['lr']\n",
    "    for i in fixed_bn_variable_bp_stats:\n",
    "        if statType == 'max':\n",
    "            ax[3].errorbar(x=max(fixed_bn_variable_bp_stats[i][0]), y=max(fixed_bn_variable_bp_stats[i][1]), label=i, fmt=markers[i], color=colors[i])\n",
    "        else:\n",
    "            if np.mean(fixed_bn_variable_bp_stats[i][0]) > plotLimits[dataset][0][1] or np.mean(fixed_bn_variable_bp_stats[i][1]) > plotLimits[dataset][1][1]:\n",
    "                ax[3].errorbar(x=np.mean(fixed_bn_variable_bp_stats[i][0]), y=np.mean(fixed_bn_variable_bp_stats[i][1]), label=i, fmt=markers[i], color=colors[i])\n",
    "            else:\n",
    "                temp = ax[3].errorbar(x=np.mean(fixed_bn_variable_bp_stats[i][0]), xerr=np.std(fixed_bn_variable_bp_stats[i][0]), y=np.mean(fixed_bn_variable_bp_stats[i][1]), yerr=np.mean(fixed_bn_variable_bp_stats[i][1]), label=i, fmt=markers[i], color=colors[i])\n",
    "                [bar.set_alpha(0.3) for bar in temp[2]]\n",
    "                [cap.set_alpha(0.3) for cap in temp[1]]\n",
    "        ax[3].set_ylim(plotLimits[dataset][1])\n",
    "        ax[3].set_xlim(plotLimits[dataset][0])\n",
    "    # D2 distribution lines\n",
    "    #if dataset != 'synthetic':\n",
    "    if metric == 'eod':\n",
    "        ax[3].axvline(x=(1.0 - files['base']['undersample']['imbalance_1.0_1.0']['original'].accuracy()))\n",
    "        ax[3].axhline(y=abs(files['base']['undersample']['imbalance_1.0_1.0']['original'].equal_opportunity_difference()))\n",
    "    elif metric == 'dp':\n",
    "        ax[3].axvline(x=(1.0 - files['base']['undersample']['imbalance_1.0_1.0']['original'].accuracy()))\n",
    "        ax[3].axhline(y=abs(files['base']['undersample']['imbalance_1.0_1.0']['original'].statistical_parity_difference()))\n",
    "    ax[3].set_xlabel('Error Rate')\n",
    "    #ax[3].set_ylabel(axisTitles[metric])\n",
    "    ax[3].set_title(r'Mean over all $β_{neg}$=1.0', fontsize=10)\n",
    "#     else:\n",
    "#         bayes_optimal_results = getBayesOptimalResults()\n",
    "#         if metric == 'eod':\n",
    "#             ax[3].axvline(x=(1.0 - bayes_optimal_results.accuracy()))\n",
    "#             ax[3].axhline(y=abs(bayes_optimal_results.equal_opportunity_difference()))\n",
    "#         elif metric == 'dp':\n",
    "#             ax[3].axvline(x=(1.0 - bayes_optimal_results.accuracy()))\n",
    "#             ax[3].axhline(y=abs(bayes_optimal_results.statistical_parity_difference()))\n",
    "#         ax[3].set_xlabel('Error Rate')\n",
    "#         ax[3].set_ylabel(axisTitles[metric])\n",
    "#         ax[3].set_title(r'Mean over all $β_{neg}$=1.0', fontsize=10)\n",
    "    \n",
    "    ################\n",
    "    # Frequency Plot\n",
    "    ################\n",
    "    cls_freqs = {}\n",
    "    for i in files:\n",
    "        cls_freqs[i] = 0\n",
    "    del cls_freqs['base']\n",
    "    for beta_pos in range(start_range,11):\n",
    "        beta_pos /= 10\n",
    "        for beta_neg in range(start_range,11):\n",
    "            beta_neg /=10\n",
    "            current_coord = {}\n",
    "            for file in files:\n",
    "                try:\n",
    "                    if metric == 'eod':\n",
    "                        current_coord[file] = (1 - files[file]['undersample'][f'imbalance_{beta_pos}_{beta_neg}']['original'].accuracy(), abs(files[file]['undersample'][f'imbalance_{beta_pos}_{beta_neg}']['original'].equal_opportunity_difference()))\n",
    "                    elif metric == 'dp':\n",
    "                        current_coord[file] = (1 - files[file]['undersample'][f'imbalance_{beta_pos}_{beta_neg}']['original'].accuracy(), abs(files[file]['undersample'][f'imbalance_{beta_pos}_{beta_neg}']['original'].statistical_parity_difference()))\n",
    "                except TypeError as te:\n",
    "                    continue\n",
    "            del current_coord['base']\n",
    "            sorted_acc = sorted(list(current_coord.items()), key=lambda x: x[1][0])\n",
    "            sorted_fairness = sorted(list(current_coord.items()), key=lambda x: x[1][1])\n",
    "            k = 5\n",
    "            top_k_classifiers = list(set([i[0] for i in sorted_acc][:k]).intersection(set([i[0] for i in sorted_fairness][:k])))\n",
    "            for i in current_coord:\n",
    "                if current_coord[i][0] < 0.5 and current_coord[i][1] < 0.5:\n",
    "                    flag = 0\n",
    "                    for j in current_coord:\n",
    "                        if j != i:\n",
    "                            # Check whether a point exists\n",
    "                            if current_coord[j][0] < current_coord[i][0] and current_coord[j][1] < current_coord[i][1]:\n",
    "                                flag = 1\n",
    "                                break\n",
    "                    if flag == 0 and i in top_k_classifiers:\n",
    "                        cls_freqs[i] += 1\n",
    "    \n",
    "    ###############################\n",
    "    # Original Split Results\n",
    "    ###############################\n",
    "    for i in files:\n",
    "        if i not in omitCls:\n",
    "            x = 1 - files[i]['undersample'][f'imbalance_1.0_1.0']['original'].accuracy()\n",
    "            if metric == 'eod':\n",
    "                y=abs(files[i]['undersample'][f'imbalance_1.0_1.0']['original'].equal_opportunity_difference())\n",
    "            elif metric == 'dp':\n",
    "                y=abs(files[i]['undersample'][f'imbalance_1.0_1.0']['original'].statistical_parity_difference())\n",
    "            if i == 'base':\n",
    "                i = 'lr'\n",
    "                continue\n",
    "            ax[0].errorbar(x, y, label=i, fmt=markers[i], color=colors[i])\n",
    "    # D2 distribution lines\n",
    "    #if dataset != 'synthetic':\n",
    "    if metric == 'eod':\n",
    "        ax[0].axvline(x=(1.0 - files['base']['undersample']['imbalance_1.0_1.0']['original'].accuracy()))\n",
    "        ax[0].axhline(y=abs(files['base']['undersample']['imbalance_1.0_1.0']['original'].equal_opportunity_difference()))\n",
    "    elif metric == 'dp':\n",
    "        ax[0].axvline(x=(1.0 - files['base']['undersample']['imbalance_1.0_1.0']['original'].accuracy()))\n",
    "        ax[0].axhline(y=abs(files['base']['undersample']['imbalance_1.0_1.0']['original'].statistical_parity_difference()))\n",
    "#     else:\n",
    "#         bayes_optimal_results = getBayesOptimalResults()\n",
    "#         if metric == 'eod':\n",
    "#             ax[0].axvline(x=(1.0 - bayes_optimal_results.accuracy()))\n",
    "#             ax[0].axhline(y=abs(bayes_optimal_results.equal_opportunity_difference()))\n",
    "#         elif metric == 'dp':\n",
    "#             ax[0].axvline(x=(1.0 - bayes_optimal_results.accuracy()))\n",
    "#             ax[0].axhline(y=abs(bayes_optimal_results.statistical_parity_difference()))\n",
    "    ax[0].set_xlabel('Error Rate')\n",
    "    ax[0].set_ylabel(axisTitles[metric])\n",
    "    ax[0].set_title('Results on Original Split', fontsize=10)\n",
    "    ax[0].set_ylim(plotLimits[dataset][1])\n",
    "    ax[0].set_xlim(plotLimits[dataset][0])\n",
    "    \n",
    "    if dataset == 'credit':\n",
    "        plt.legend(bbox_to_anchor=(1.1,1.1))\n",
    "    elif dataset == 'adult':\n",
    "        plt.legend(loc='right', bbox_to_anchor=(2.1,0.5))\n",
    "    elif dataset == 'compas':\n",
    "        plt.legend(loc='right', bbox_to_anchor=(2.1,0.5))\n",
    "    elif dataset == 'bank':\n",
    "        plt.legend(loc='right', bbox_to_anchor=(2.1,0.5))\n",
    "    elif dataset == 'synthetic':\n",
    "        plt.legend(loc='right', bbox_to_anchor=(2.1,0.5))\n",
    "    plt.show()\n",
    "    \n",
    "    if lessBiasMode == True:\n",
    "        fig.savefig(f'{dataset}_{metric}_lessBias_underRepresentation.png', dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        fig.savefig(f'{dataset}_{metric}_underRepresentation.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Dump Pareto Plot data\n",
    "    with open(f'pareto_{dataset}_{metric}.pkl', 'wb') as f:\n",
    "        pickle.dump(cls_freqs, f)\n",
    "    plt.figure()\n",
    "    plt.bar(range(len(cls_freqs)), cls_freqs.values(), tick_label=list(cls_freqs.keys()))\n",
    "    plt.xticks(rotation=90, fontsize=8)\n",
    "    plt.title('Pareto Optimality Frequency', fontsize=9)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "try:\n",
    "    del files\n",
    "    gc.collect()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "dataset='credit'\n",
    "if dataset == 'bank':\n",
    "    files={\n",
    "        'base': f'/media/data_dump/anonymous/aaai_2023_data/results/base__eop__{dataset}__lr.pkl',\n",
    "        'jiang_nachum': f'/media/data_dump/anonymous/aaai_2023_data/results/jiang_nachum__eop__{dataset}__lr.pkl',\n",
    "        'rew':f'/media/data_dump/anonymous/aaai_2023_data/results/rew__eop__{dataset}__lr.pkl',\n",
    "        'exp_grad_eodds':f'/media/data_dump/anonymous/aaai_2023_data/results/exp_grad__eodds__{dataset}__lr.pkl',\n",
    "        'meta_fair_fdr':f'/media/data_dump/anonymous/aaai_2023_data/results/meta_fair__fdr__{dataset}__lr.pkl',\n",
    "        'prej_remover':f'/media/data_dump/anonymous/aaai_2023_data/results/prej_remover__eop__{dataset}__lr.pkl',\n",
    "        'gerry_fair': f'/media/data_dump/anonymous/aaai_2023_data/results/gerry_fair__eop__{dataset}__lr.pkl',\n",
    "        'cal_eq':f'/media/data_dump/anonymous/aaai_2023_data/results/cal_eq__eop__{dataset}__lr.pkl',\n",
    "        'eq':f'/media/data_dump/anonymous/aaai_2023_data/results/eq__eop__{dataset}__lr.pkl',\n",
    "        'reject':f'/media/data_dump/anonymous/aaai_2023_data/results/reject__eop__{dataset}__lr.pkl',\n",
    "    }\n",
    "else:\n",
    "    files={\n",
    "        'base': f'/media/data_dump/anonymous/aaai_2023_data/results/base__eop__{dataset}__lr.pkl',\n",
    "        'jiang_nachum': f'/media/data_dump/anonymous/aaai_2023_data/results/jiang_nachum__eop__{dataset}__lr.pkl',\n",
    "        'rew':f'/media/data_dump/anonymous/aaai_2023_data/results/rew__eop__{dataset}__lr.pkl',\n",
    "        'fairgan':f'/media/data_dump/anonymous/aaai_2023_data/results/fairgan__eop__{dataset}__lr.pkl',\n",
    "        'exp_grad_eodds':f'/media/data_dump/anonymous/aaai_2023_data/results/exp_grad__eodds__{dataset}__lr.pkl',\n",
    "        'meta_fair_fdr':f'/media/data_dump/anonymous/aaai_2023_data/results/meta_fair__fdr__{dataset}__lr.pkl',\n",
    "        'prej_remover':f'/media/data_dump/anonymous/aaai_2023_data/results/prej_remover__eop__{dataset}__lr.pkl',\n",
    "        'gerry_fair': f'/media/data_dump/anonymous/aaai_2023_data/results/gerry_fair__eop__{dataset}__lr.pkl',\n",
    "        'cal_eq':f'/media/data_dump/anonymous/aaai_2023_data/results/cal_eq__eop__{dataset}__lr.pkl',\n",
    "        'eq':f'/media/data_dump/anonymous/aaai_2023_data/results/eq__eop__{dataset}__lr.pkl',\n",
    "        'reject':f'/media/data_dump/anonymous/aaai_2023_data/results/reject__eop__{dataset}__lr.pkl',\n",
    "    }\n",
    "for i in files:\n",
    "    with open(files[i], 'rb') as f:\n",
    "        files[i] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric='eod'\n",
    "if metric == 'eod':\n",
    "    plotLimits = {\n",
    "            'synthetic': ([-0.05, 0.3], [-0.03,0.2]),\n",
    "            'adult': ([0, 0.4], [-0.01, 0.25]),\n",
    "            'bank': ([0, 0.5], [-0.01, 0.35]),\n",
    "            'compas': ([0.05, 0.5], [-0.01, 0.2]),\n",
    "            'credit': ([0, 0.4], [-0.01, 0.2])\n",
    "        }\n",
    "else:\n",
    "    plotLimits = {\n",
    "            'synthetic': ([-0.1, 0.55], [0, 0.4]),\n",
    "            'adult': ([-0.1, 0.38], [-0.01, 0.4]),\n",
    "            'bank': ([0, 0.6], [-0.01, 0.4]),\n",
    "            'compas': ([0.05, 0.5], [-0.01, 0.3]),\n",
    "            'credit': ([0, 0.4], [-0.01, 0.2])\n",
    "        }\n",
    "max_mean_plots(files, metric=metric, dataset=dataset, plotLimits=plotLimits, lessBiasMode=True)\n",
    "#max_mean_plots(files, metric=metric, dataset=dataset, plotLimits=plotLimits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a6bf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotParetoBars(mode='', metric='', lessBiasMode=False):\n",
    "    plt.figure(figsize=(20,3))\n",
    "    perClassifierResults = {}\n",
    "    if mode == 'labelBias':\n",
    "        with open(f'pareto_labelBias_adult_{metric}.pkl', 'rb') as f:\n",
    "            cls_freqs = pickle.load(f)\n",
    "    else:\n",
    "        with open(f'pareto_adult_{metric}.pkl', 'rb') as f:\n",
    "            cls_freqs = pickle.load(f)\n",
    "    labels = list(cls_freqs.keys())\n",
    "    width = 0.4\n",
    "    eps = 0.6\n",
    "    x_axis = [0]*len(labels)\n",
    "    for i in range(len(labels)):\n",
    "        x_axis[i] = i*(width*6)\n",
    "        if i != 0:\n",
    "            x_axis[i] += width*i\n",
    "    x_axis = np.asarray(x_axis)\n",
    "    avgList = None\n",
    "    for index, dataset in enumerate(['synthetic', 'adult', 'bank', 'compas', 'credit']):\n",
    "        if mode == 'labelBias':\n",
    "            with open(f'pareto_labelBias_{dataset}_{metric}.pkl', 'rb') as f:\n",
    "                cls_freqs = pickle.load(f)\n",
    "        else:\n",
    "            with open(f'pareto_{dataset}_{metric}.pkl', 'rb') as f:\n",
    "                cls_freqs = pickle.load(f)\n",
    "        y_data = []\n",
    "        for i in labels:\n",
    "            if i in cls_freqs:\n",
    "                y_data.append(cls_freqs[i])\n",
    "            else:\n",
    "                y_data.append(0)\n",
    "        if avgList is None:\n",
    "            avgList = y_data\n",
    "        else:\n",
    "            for j,_ in enumerate(y_data):\n",
    "                avgList[j] += y_data[j]\n",
    "        plt.bar(x_axis + index*width, y_data, label=dataset, width=width, edgecolor='white')\n",
    "        if index == 4:\n",
    "            for j,_ in enumerate(avgList):\n",
    "                avgList[j] /= 5\n",
    "            plt.bar(x_axis + (index + 1)*width, avgList, label='average', width=width, edgecolor='white')\n",
    "    \n",
    "    # Draw vertical lines\n",
    "    for i in x_axis:\n",
    "        plt.axvline(x=i + (index+1)*width + width, color='gray')\n",
    "    plt.xticks(x_axis + 2*width, labels, rotation=30, fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.legend(fontsize=13)\n",
    "    #plt.title('Pareto Optimality Frequency', fontsize=9)\n",
    "    plt.xlim([-width,x_axis[-1]+6*width])\n",
    "    plt.grid()\n",
    "    plt.ylabel('Frequency', fontsize=15)\n",
    "    if mode != 'labelBias':\n",
    "        if lessBiasMode == False:\n",
    "            plt.savefig(f'underRepresentation_pareto_{metric}.png', dpi=300, bbox_inches='tight')\n",
    "        else:\n",
    "            plt.savefig(f'underRepresentation_pareto_{metric}_lessBiasMode.png', dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        if lessBiasMode == False:\n",
    "            plt.savefig(f'labelBias_pareto_{metric}.png', dpi=300, bbox_inches='tight')\n",
    "        else:\n",
    "            plt.savefig(f'labelBias_pareto_{metric}_lessBiasMode.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced14a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotParetoBars(metric='eod', lessBiasMode=True)\n",
    "#plotParetoBars(metric='dp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d135756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelBias_max_mean_plots(files, metric='eod', testSet='orig', dataset='synthetic', statType='mean', plotLimits=None, lessBiasMode=False):\n",
    "    if dataset == 'compas':\n",
    "        omitCls = ['meta_fair_fdr']\n",
    "    else:\n",
    "        omitCls = []\n",
    "    axisTitles = {\n",
    "        'dp': 'Statistical Parity Diff.',\n",
    "        'eod': 'Equal Opportunity Difference'\n",
    "    }\n",
    "    markers = {\n",
    "        'lr': '+',\n",
    "        'jiang_nachum': 'o',\n",
    "        'rew':'o',\n",
    "        'fairgan':'o',\n",
    "        'exp_grad_eodds':'^',\n",
    "        'meta_fair_fdr':'^',\n",
    "        'prej_remover':'^',\n",
    "        'gerry_fair': '^',\n",
    "        'cal_eq':'s',\n",
    "        'eq':'s',\n",
    "        'reject':'s'\n",
    "    }\n",
    "    colors = {\n",
    "        'lr': '#1f77b4',\n",
    "        'jiang_nachum': '#ff7f0e',\n",
    "        'rew':'#2ca02c',\n",
    "        'fairgan':'#d62728',\n",
    "        'exp_grad_eodds':'#9467bd',\n",
    "        'meta_fair_fdr':'#8c564b',\n",
    "        'prej_remover':'#e377c2',\n",
    "        'gerry_fair': '#7f7f7f',\n",
    "        'cal_eq':'#bcbd22',\n",
    "        'eq':'#17becf',\n",
    "        'reject':'#1f77b4'\n",
    "    }\n",
    "    fig, ax = plt.subplots(ncols=2)\n",
    "    fig.subplots_adjust(wspace=0.3)\n",
    "    fig.set_figheight(3)\n",
    "    fig.set_figwidth(6)\n",
    "    overallStats = {}\n",
    "    for file in files:\n",
    "        if file == 'base':\n",
    "            file='lr'\n",
    "        if file not in omitCls:\n",
    "            overallStats[file] = [[],[]]\n",
    "    if lessBiasMode == True:\n",
    "        end_range=5\n",
    "    else:\n",
    "        end_range = 10\n",
    "    for lb,label_bias in enumerate(range(0,end_range)):\n",
    "        label_bias /= 10\n",
    "        # Calculating required Quantities\n",
    "        for file in files:\n",
    "            if file in omitCls:\n",
    "                continue\n",
    "            results = files[file]\n",
    "            try:\n",
    "                if metric == 'dp':\n",
    "                    y_bal = abs(results['label_bias'][f'imbalance_{str(label_bias)}']['balanced'].statistical_parity_difference())\n",
    "                    y_biased = abs(results['label_bias'][f'imbalance_{str(label_bias)}']['biased'].statistical_parity_difference())\n",
    "                    y_orig = abs(results['label_bias'][f'imbalance_{str(label_bias)}']['original'].statistical_parity_difference())\n",
    "                elif metric == 'eod':\n",
    "                    y_bal = abs(results['label_bias'][f'imbalance_{str(label_bias)}']['balanced'].equal_opportunity_difference())\n",
    "                    y_biased = abs(results['label_bias'][f'imbalance_{str(label_bias)}']['biased'].equal_opportunity_difference())\n",
    "                    y_orig = abs(results['label_bias'][f'imbalance_{str(label_bias)}']['original'].equal_opportunity_difference())\n",
    "                # Calculate accuracy\n",
    "                x_err_rate_bal = (1 - abs(results['label_bias'][f'imbalance_{str(label_bias)}']['balanced'].accuracy()))\n",
    "                x_err_rate_biased = (1 - abs(results['label_bias'][f'imbalance_{str(label_bias)}']['biased'].accuracy()))\n",
    "                x_err_rate_orig = (1 - abs(results['label_bias'][f'imbalance_{str(label_bias)}']['original'].accuracy()))\n",
    "            except TypeError as te:\n",
    "                continue\n",
    "            if testSet == 'bal':\n",
    "                y = y_bal\n",
    "                x = x_err_rate_bal\n",
    "            elif testSet == 'biased':\n",
    "                y = y_biased\n",
    "                x = x_err_rate_biased\n",
    "            elif testSet == 'orig':\n",
    "                y = y_orig\n",
    "                x = x_err_rate_orig\n",
    "            if file == 'base':\n",
    "                file='lr'\n",
    "            overallStats[file][0].append(x)\n",
    "            overallStats[file][1].append(y)\n",
    "    ##############\n",
    "    # Overall Mean\n",
    "    ##############\n",
    "    del overallStats['lr']\n",
    "    for i in overallStats:\n",
    "        if statType == 'max':\n",
    "            ax[1].errorbar(x=max(overallStats[i][0]), y=max(overallStats[i][1]), label=i, fmt=markers[i], color=colors[i])\n",
    "        else:\n",
    "            if np.mean(overallStats[i][0]) > plotLimits[dataset][0][1] or np.mean(overallStats[i][1]) > plotLimits[dataset][1][1]:\n",
    "                ax[1].errorbar(x=np.mean(overallStats[i][0]), y=np.mean(overallStats[i][1]), label=i, fmt=markers[i], color=colors[i])\n",
    "            else:\n",
    "                temp = ax[1].errorbar(x=np.mean(overallStats[i][0]), y=np.mean(overallStats[i][1]), xerr=np.std(overallStats[i][0]), yerr=np.std(overallStats[i][1]), label=i, fmt=markers[i], color=colors[i])\n",
    "                [bar.set_alpha(0.3) for bar in temp[2]]\n",
    "                [cap.set_alpha(0.3) for cap in temp[1]]\n",
    "        ax[1].set_ylim(plotLimits[dataset][1])\n",
    "        ax[1].set_xlim(plotLimits[dataset][0])\n",
    "    # D2 distribution lines\n",
    "    #if dataset != 'synthetic':\n",
    "    if metric == 'eod':\n",
    "        ax[1].axvline(x=(1.0 - files['base']['label_bias']['imbalance_0.0']['original'].accuracy()))\n",
    "        ax[1].axhline(y=abs(files['base']['label_bias']['imbalance_0.0']['original'].equal_opportunity_difference()))\n",
    "    elif metric == 'dp':\n",
    "        ax[1].axvline(x=(1.0 - files['base']['label_bias']['imbalance_0.0']['original'].accuracy()))\n",
    "        ax[1].axhline(y=abs(files['base']['label_bias']['imbalance_0.0']['original'].statistical_parity_difference()))\n",
    "    ax[1].set_xlabel('Error Rate')\n",
    "    #ax[1].set_ylabel(axisTitles[metric])\n",
    "    ax[1].set_title('Mean Over all settings', fontsize=10)\n",
    "#     else:\n",
    "#         bayes_optimal_results = getBayesOptimalResults()\n",
    "#         if metric == 'eod':\n",
    "#             ax[1].axvline(x=(1.0 - bayes_optimal_results.accuracy()))\n",
    "#             ax[1].axhline(y=abs(bayes_optimal_results.equal_opportunity_difference()))\n",
    "#         elif metric == 'dp':\n",
    "#             ax[1].axvline(x=(1.0 - bayes_optimal_results.accuracy()))\n",
    "#             ax[1].axhline(y=abs(bayes_optimal_results.statistical_parity_difference()))\n",
    "#         ax[1].set_xlabel('Error Rate')\n",
    "#         ax[1].set_ylabel(axisTitles[metric])\n",
    "#         ax[1].set_title('Mean Over all settings', fontsize=10)\n",
    "    \n",
    "    ################\n",
    "    # Frequency Plot\n",
    "    ################\n",
    "    cls_freqs = {}\n",
    "    for i in files:\n",
    "        cls_freqs[i] = 0\n",
    "    del cls_freqs['base']\n",
    "    for label_bias in range(0,end_range):\n",
    "        label_bias /= 10\n",
    "        current_coord = {}\n",
    "        for file in files:\n",
    "            try:\n",
    "                if metric == 'eod':\n",
    "                    current_coord[file] = (1 - files[file]['label_bias'][f'imbalance_{label_bias}']['original'].accuracy(), abs(files[file]['label_bias'][f'imbalance_{label_bias}']['original'].equal_opportunity_difference()))\n",
    "                elif metric == 'dp':\n",
    "                    current_coord[file] = (1 - files[file]['label_bias'][f'imbalance_{label_bias}']['original'].accuracy(), abs(files[file]['label_bias'][f'imbalance_{label_bias}']['original'].statistical_parity_difference()))\n",
    "            except TypeError as te:\n",
    "                continue\n",
    "        del current_coord['base']\n",
    "        sorted_acc = sorted(list(current_coord.items()), key=lambda x: x[1][0])\n",
    "        sorted_fairness = sorted(list(current_coord.items()), key=lambda x: x[1][1])\n",
    "        k = 5\n",
    "        top_k_classifiers = list(set([i[0] for i in sorted_acc][:k]).intersection(set([i[0] for i in sorted_fairness][:k])))\n",
    "        for i in current_coord:\n",
    "            if current_coord[i][0] < 0.5 and current_coord[i][1] < 0.5:\n",
    "                flag = 0\n",
    "                for j in current_coord:\n",
    "                    if j != i:\n",
    "                        # Check whether a point exists\n",
    "                        if current_coord[j][0] < current_coord[i][0] and current_coord[j][1] < current_coord[i][1]:\n",
    "                            flag = 1\n",
    "                            break\n",
    "                if flag == 0 and i in top_k_classifiers:\n",
    "                    cls_freqs[i] += 1\n",
    "\n",
    "    ###############################\n",
    "    # Original Split Results\n",
    "    ###############################\n",
    "    for i in files:\n",
    "        if i not in omitCls:\n",
    "            x = 1 - files[i]['label_bias'][f'imbalance_0.0']['original'].accuracy()\n",
    "            if metric == 'eod':\n",
    "                y=abs(files[i]['label_bias'][f'imbalance_0.0']['original'].equal_opportunity_difference())\n",
    "            elif metric == 'dp':\n",
    "                y=abs(files[i]['label_bias'][f'imbalance_0.0']['original'].statistical_parity_difference())\n",
    "            if i == 'base':\n",
    "                i = 'lr'\n",
    "            ax[0].errorbar(x,y, label=i, fmt=markers[i], color=colors[i])\n",
    "    # D2 distribution lines\n",
    "    #if dataset != 'synthetic':\n",
    "    if metric == 'eod':\n",
    "        ax[0].axvline(x=(1.0 - files['base']['label_bias']['imbalance_0.0']['original'].accuracy()))\n",
    "        ax[0].axhline(y=abs(files['base']['label_bias']['imbalance_0.0']['original'].equal_opportunity_difference()))\n",
    "    elif metric == 'dp':\n",
    "        ax[0].axvline(x=(1.0 - files['base']['label_bias']['imbalance_0.0']['original'].accuracy()))\n",
    "        ax[0].axhline(y=abs(files['base']['label_bias']['imbalance_0.0']['original'].statistical_parity_difference()))\n",
    "#     else:\n",
    "#         bayes_optimal_results = getBayesOptimalResults()\n",
    "#         if metric == 'eod':\n",
    "#             ax[0].axvline(x=(1.0 - bayes_optimal_results.accuracy()))\n",
    "#             ax[0].axhline(y=abs(bayes_optimal_results.equal_opportunity_difference()))\n",
    "#         elif metric == 'dp':\n",
    "#             ax[0].axvline(x=(1.0 - bayes_optimal_results.accuracy()))\n",
    "#             ax[0].axhline(y=abs(bayes_optimal_results.statistical_parity_difference()))\n",
    "    ax[0].set_xlabel('Error Rate')\n",
    "    ax[0].set_ylabel(axisTitles[metric])\n",
    "    ax[0].set_title('Results on Original Split', fontsize=10)\n",
    "    ax[0].set_ylim(plotLimits[dataset][1])\n",
    "    ax[0].set_xlim(plotLimits[dataset][0])\n",
    "    \n",
    "    if dataset == 'credit':\n",
    "        plt.legend(bbox_to_anchor=(1.1,1.1))\n",
    "    elif dataset == 'adult':\n",
    "        plt.legend(loc='right', bbox_to_anchor=(2.1,0.5))\n",
    "    elif dataset == 'compas':\n",
    "        plt.legend(loc='right', bbox_to_anchor=(2.1,0.5))\n",
    "    elif dataset == 'bank':\n",
    "        plt.legend(loc='right', bbox_to_anchor=(2.1,0.5))\n",
    "    elif dataset == 'synthetic':\n",
    "        plt.legend(loc='right', bbox_to_anchor=(2.1,0.5))\n",
    "    plt.show()\n",
    "    \n",
    "    if lessBiasMode == True:\n",
    "        fig.savefig(f'{dataset}_{metric}_lessBias_labelBias.png', dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        fig.savefig(f'{dataset}_{metric}_labelBias.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Dump Pareto Plot data\n",
    "    with open(f'pareto_labelBias_{dataset}_{metric}.pkl', 'wb') as f:\n",
    "        pickle.dump(cls_freqs, f)\n",
    "    plt.figure()\n",
    "    plt.bar(range(len(cls_freqs)), cls_freqs.values(), tick_label=list(cls_freqs.keys()))\n",
    "    plt.xticks(rotation=90, fontsize=8)\n",
    "    plt.title('Pareto Optimality Frequency', fontsize=9)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82df830",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'eod'\n",
    "if metric == 'eod':\n",
    "    plotLimits = {\n",
    "        'synthetic': ([0, 0.2], [-0.05, 0.4]),\n",
    "        'adult': ([0, 0.35], [-0.01, 0.2]),\n",
    "        'bank': ([0, 0.15], [-0.01, 0.1]),\n",
    "        'compas': ([0.05, 0.55], [-0.01, 0.2]),\n",
    "        'credit': ([0, 0.4], [-0.01, 0.3])\n",
    "    }\n",
    "else:\n",
    "    plotLimits = {\n",
    "            'synthetic': ([-0.05, 0.25], [0.15,0.4]),\n",
    "            'adult': ([-0.1, 0.4], [-0.01, 0.3]),\n",
    "            'bank': ([0, 0.15], [-0.01, 0.1]),\n",
    "            'compas': ([0.05, 0.5], [-0.01, 0.3]),\n",
    "            'credit': ([0, 0.4], [-0.02, 0.3])\n",
    "        }\n",
    "labelBias_max_mean_plots(files, metric=metric, dataset=dataset, plotLimits=plotLimits, lessBiasMode=True)\n",
    "#labelBias_max_mean_plots(files, metric=metric, dataset=dataset, plotLimits=plotLimits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotParetoBars(mode='labelBias', metric='eod', lessBiasMode=True)\n",
    "#plotParetoBars(mode='labelBias', metric='dp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14795c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
